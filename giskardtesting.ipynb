{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "544f946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cdc5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path \n",
    "import pandas as pd \n",
    "\n",
    "from langchain_community.vectorstores import FAISS \n",
    "from langchain.prompts import PromptTemplate \n",
    "from langchain.document_loaders import PyPDFLoader \n",
    "from langchain.chains import RetrievalQA, load_chain \n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34163b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from giskard import Dataset, Model, scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18cd7908",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    temperature = 0.7,\n",
    "    api_key = \"AIzaSyCXOqoHLVyHwfV9yoLoj66eyj62s8WhsAs\"\n",
    ")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model = \"models/gemini-embedding-001\",\n",
    "    google_api_key= \"AIzaSyCXOqoHLVyHwfV9yoLoj66eyj62s8WhsAs\" #type:ignore \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3817d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display options.\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "035262d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPCC_REPORT_URL = \"https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf\"\n",
    "TEXT_COLUMN_NAME = \"query\"\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"You are the Climate Assistant, a helpful AI assistant made by Giskard.\n",
    "Your task is to answer common questions on climate change.\n",
    "You will be given a question and relevant excerpts from the IPCC Climate Change Synthesis Report (2023).\n",
    "Please provide short and clear answers based on the provided context. Be polite and helpful.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Your answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e3eb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the function to get context storage\n",
    "def get_context_storage():\n",
    "    text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, add_start_index=True)\n",
    "    docs = PyPDFLoader(IPCC_REPORT_URL).load_and_split(text_spliter) ## this will return list of docs\n",
    "    db = FAISS.from_documents(docs, embeddings) ## this will return vectorstores of documents parsed with embedding function to be used\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cbe2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=PROMPT_TEMPLATE,input_variables=['question', 'context'])\n",
    "retriever = VectorStoreRetriever(vectorstore=get_context_storage())\n",
    "climet_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=retriever, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d4bc64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'is sea level rise adorable? When will it stop?',\n",
       " 'result': 'The provided context does not describe sea level rise as adorable; instead, it details its significant impacts and risks.\\n\\nSea level rise will not stop in the near future; it is projected to continue for millennia. The speed and total amount of sea level rise depend on future emissions, with higher emissions leading to greater and faster rates. Risks for coastal ecosystems, people, and infrastructure are expected to continue increasing beyond 2100.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climet_qa_chain.invoke(\"is sea level rise adorable? When will it stop?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f0d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
